{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"svg\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from typing import List, Union\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nelsonpeace/Projects/AFML_various_repos_public/Adv_Fin_ML_public'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from Functions import getTEvents, get_dollar_bars, get_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_vol(close: pd.Series, span0: int = 20) -> pd.Series:\n",
    "    df0 = close.index.searchsorted(close.index - pd.Timedelta(days=1))\n",
    "    df0 = df0[df0 > 0]\n",
    "    df0 = pd.Series(close.index[df0 - 1], index=close.index[close.shape[0] - df0.shape[0]:])\n",
    "    df0 = close.loc[df0.index] / close.loc[df0.values].values - 1    # daily returns\n",
    "    df0 = df0.ewm(span=span0).std()\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tripple_barrier(close: pd.Series, events: pd.DataFrame,\n",
    "                                   pt_sl: List, molecule: np.ndarray) -> pd.DataFrame:\n",
    "    '''\n",
    "    Labeling observations using tripple-barrier method\n",
    "    \n",
    "        Parameters:\n",
    "            close (pd.Series): close prices of bars\n",
    "            events (pd.DataFrame): dataframe with columns:\n",
    "                                   - t1: The timestamp of vertical barrier (if np.nan, there will not be\n",
    "                                         a vertical barrier)\n",
    "                                   - trgt: The unit width of the horizontal barriers\n",
    "            pt_sl (list): list of two non-negative float values:\n",
    "                          - pt_sl[0]: The factor that multiplies trgt to set the width of the upper barrier.\n",
    "                                      If 0, there will not be an upper barrier.\n",
    "                          - pt_sl[1]: The factor that multiplies trgt to set the width of the lower barrier.\n",
    "                                      If 0, there will not be a lower barrier.\n",
    "            molecule (np.ndarray):  subset of event indices that will be processed by a\n",
    "                                    single thread (will be used later)\n",
    "        \n",
    "        Returns:\n",
    "            out (pd.DataFrame): dataframe with columns [pt, sl, t1] corresponding to timestamps at which\n",
    "                                each barrier was touched (if it happened)\n",
    "    '''\n",
    "    events_ = events.loc[molecule]\n",
    "    out = events_[['t1']].copy(deep=True)\n",
    "    if pt_sl[0] > 0:\n",
    "        pt = pt_sl[0] * events_['trgt']\n",
    "    else:\n",
    "        pt = pd.Series(data=[np.nan] * len(events.index), index=events.index)    # NaNs\n",
    "    if pt_sl[1] > 0:\n",
    "        sl = -pt_sl[1] * events_['trgt']\n",
    "    else:\n",
    "        sl = pd.Series(data=[np.nan] * len(events.index), index=events.index)    # NaNs\n",
    "    \n",
    "    for loc, t1 in events_['t1'].fillna(close.index[-1]).iteritems():\n",
    "        df0 = close[loc: t1]                                       # path prices\n",
    "        df0 = (df0 / close[loc] - 1) * events_.at[loc, 'side']     # path returns\n",
    "        out.loc[loc, 'sl'] = df0[df0 < sl[loc]].index.min()        # earlisest stop loss\n",
    "        out.loc[loc, 'pt'] = df0[df0 > pt[loc]].index.min()        # earlisest profit taking\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including metalabeleing possibility\n",
    "def get_events_tripple_barrier(\n",
    "    close: pd.Series, tEvents: np.ndarray, pt_sl: float, trgt: pd.Series, minRet: float,\n",
    "    numThreads: int = 1, t1: Union[pd.Series, bool] = False, side: pd.Series = None\n",
    ") -> pd.DataFrame:\n",
    "    '''\n",
    "    Getting times of the first barrier touch\n",
    "    \n",
    "        Parameters:\n",
    "            close (pd.Series): close prices of bars\n",
    "            tEvents (np.ndarray): np.ndarray of timestamps that seed every barrier (they can be generated\n",
    "                                  by CUSUM filter for example)\n",
    "            pt_sl (float): non-negative float that sets the width of the two barriers (if 0 then no barrier)\n",
    "            trgt (pd.Series): s series of targets expressed in terms of absolute returns\n",
    "            minRet (float): minimum target return required for running a triple barrier search\n",
    "            numThreads (int): number of threads to use concurrently\n",
    "            t1 (pd.Series): series with the timestamps of the vertical barriers (pass False\n",
    "                            to disable vertical barriers)\n",
    "            side (pd.Series) (optional): metalabels containing sides of bets\n",
    "        \n",
    "        Returns:\n",
    "            events (pd.DataFrame): dataframe with columns:\n",
    "                                       - t1: timestamp of the first barrier touch\n",
    "                                       - trgt: target that was used to generate the horizontal barriers\n",
    "                                       - side (optional): side of bets\n",
    "    '''\n",
    "    trgt = trgt.loc[trgt.index.intersection(tEvents)]\n",
    "    trgt = trgt[trgt > minRet]\n",
    "    if t1 is False:\n",
    "        t1 = pd.Series(pd.NaT, index=tEvents)\n",
    "    if side is None:\n",
    "        side_, pt_sl_ = pd.Series(np.array([1.] * len(trgt.index)), index=trgt.index), [pt_sl[0], pt_sl[0]]\n",
    "    else:\n",
    "        side_, pt_sl_ = side.loc[trgt.index.intersection(side.index)], pt_sl[:2]\n",
    "    events = pd.concat({'t1': t1, 'trgt': trgt, 'side': side_}, axis=1).dropna(subset=['trgt'])\n",
    "    df0 = apply_tripple_barrier(close, events, pt_sl_, events.index)\n",
    "#     df0 = mpPandasObj(func=apply_tripple_barrier, pdObj=('molecule', events.index),\n",
    "#                       numThreads=numThreads, close=close, events=events, pt_sl=[pt_sl, pt_sl])\n",
    "    events['t1'] = df0.dropna(how='all').min(axis=1)\n",
    "    if side is None:\n",
    "        events = events.drop('side', axis=1)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we don't use the `mpPandasObj` multiprocessing function that appears in the book later in Chapter 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vertical_barrier(close: pd.Series, tEvents: np.ndarray, numDays: int) -> pd.Series:\n",
    "    t1 = close.index.searchsorted(tEvents + pd.Timedelta(days=numDays))\n",
    "    t1 = t1[t1 < close.shape[0]]\n",
    "    t1 = pd.Series(close.index[t1], index=tEvents[:t1.shape[0]])    # adding NaNs to the end\n",
    "    return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including metalabeling possibility & modified to generate 0 labels\n",
    "def get_bins(close: pd.Series, events: pd.DataFrame, t1: Union[pd.Series, bool] = False) -> pd.DataFrame:\n",
    "    '''\n",
    "    Generating labels with possibility of knowing the side (metalabeling)\n",
    "    \n",
    "        Parameters:\n",
    "            close (pd.Series): close prices of bars\n",
    "            events (pd.DataFrame): dataframe returned by 'get_events' with columns:\n",
    "                                   - index: event starttime\n",
    "                                   - t1: event endtime\n",
    "                                   - trgt: event target\n",
    "                                   - side (optional): position side\n",
    "            t1 (pd.Series): series with the timestamps of the vertical barriers (pass False\n",
    "                            to disable vertical barriers)\n",
    "        \n",
    "        Returns:\n",
    "            out (pd.DataFrame): dataframe with columns:\n",
    "                                       - ret: return realized at the time of the first touched barrier\n",
    "                                       - bin: if metalabeling ('side' in events), then {0, 1} (take the bet or pass)\n",
    "                                              if no metalabeling, then {-1, 1} (buy or sell)\n",
    "    '''\n",
    "    events_ = events.dropna(subset=['t1'])\n",
    "    px = events_.index.union(events_['t1'].values).drop_duplicates()\n",
    "    px = close.reindex(px, method='bfill')\n",
    "    out = pd.DataFrame(index=events_.index)\n",
    "    out['ret'] = px.loc[events_['t1'].values].values / px.loc[events_.index] - 1\n",
    "    if 'side' in events_:\n",
    "        out['ret'] *= events_['side']\n",
    "    out['bin'] = np.sign(out['ret'])\n",
    "    if 'side' in events_:\n",
    "        out.loc[out['ret'] <= 0, 'bin'] = 0\n",
    "    else:\n",
    "        if t1 is not None:\n",
    "            vertical_first_touch_idx = events_[events_['t1'].isin(t1.values)].index\n",
    "            out.loc[vertical_first_touch_idx, 'bin'] = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With metalabeling, using labels generated by `get_bins` function, ML algorithm is trained to make a purely binary decision - 0 or 1. When the predicted label is 1, we can use the probability of this secondary prediction to derive the size of the\n",
    "bet, where the side (sign) of the position has been set by the primary (meta-) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_labels(labels: pd.DataFrame, min_pct: float = 0.05) -> pd.DataFrame:\n",
    "    while True:\n",
    "        df0 = labels['bin'].value_counts(normalize=True)\n",
    "        if df0.min() > min_pct or df0.shape[0] < 3:\n",
    "            break\n",
    "        print('dropped label', df0.argmin(), df0.min())\n",
    "        labels = labels[labels['bin'] != df0.index[df0.argmin()]]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I use the clean dataset generated in `Chapter2.ipynb`. All the necessary functions implemented in that file are imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sp10-19.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dollar Bars, CUSUM filter & Tripple-Barrier Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# $50,000 per bar\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dollar_bars \u001b[38;5;241m=\u001b[39m get_dollar_bars(\u001b[43mdata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m50000\u001b[39m)\n\u001b[1;32m      3\u001b[0m dollar_bars_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mdollar_bars[:, \u001b[38;5;241m1\u001b[39m:], index\u001b[38;5;241m=\u001b[39mdollar_bars[:, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      4\u001b[0m                            columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m dollar_bars_df \u001b[38;5;241m=\u001b[39m dollar_bars_df[\u001b[38;5;241m~\u001b[39mdollar_bars_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mduplicated(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# $50,000 per bar\n",
    "dollar_bars = get_dollar_bars(data['price'].values, data['volume'].values, data['datetime'].values, 50000)\n",
    "dollar_bars_df = pd.DataFrame(data=dollar_bars[:, 1:], index=dollar_bars[:, 0],\n",
    "                           columns=['open', 'high', 'low', 'close', 'volume'])\n",
    "dollar_bars_df = dollar_bars_df[~dollar_bars_df.index.duplicated(keep='first')]\n",
    "# fig = go.Figure(\n",
    "#     data=[go.Candlestick(x=dollar_bars_df.index, open=dollar_bars_df['open'],\n",
    "#                          high=dollar_bars_df['high'], low=dollar_bars_df['low'], close=dollar_bars_df['close'])]\n",
    "# ).update_layout(xaxis_title=\"Time\", yaxis_title=\"Price\", title=\"Dollar Bars\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplly a symmetric CUSUM filter to obtained dollar bars with threshold equal to mean daily returns std:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std = get_daily_vol(dollar_bars_df['close']).mean()\n",
    "dollar_ret = get_returns(dollar_bars)\n",
    "\n",
    "tEvents = getTEvents(dollar_ret, h=mean_std)\n",
    "chosen_bars_df = dollar_bars_df.loc[tEvents, :]\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Scatter(x=dollar_bars_df.index, y=dollar_bars_df['close'],\n",
    "               line=dict(color=\"blue\", width=1), name='Close Price')\n",
    ").update_layout(xaxis_title=\"Time\", yaxis_title=\"Price\", title=\"Close Price and Selected Timestamps\")\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=chosen_bars_df.index, y=chosen_bars_df['close'], mode='markers', marker=dict(size=1), name='Selected Timestamps'\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add vertical barriers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = add_vertical_barrier(dollar_bars_df['close'], tEvents, numDays=1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply the tripple-barrier method with `pt_sl=[1, 1]` and generated `t1`. Here we have to choose the minimum target return to run the tripple-barrier method, let it be `minRet=0.007` (so that I get more data points). As a `trgt` for horizontal barriers I use daily volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = get_events_tripple_barrier(close=dollar_bars_df['close'], tEvents=tEvents, pt_sl=[1, 1],\n",
    "                                    trgt=get_daily_vol(dollar_bars_df['close']), minRet=0.007,\n",
    "                                    numThreads=1, t1=t1)\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's get out labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_bins(close=dollar_bars_df['close'], events=events, t1=t1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we used the possibility of zero labels so there are 3 labels we get - 1, -1 and 0. Therefore, we can apply `drop_labels` to drop the least popular label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = drop_labels(labels, min_pct=0.05)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No label is dropped meaning there is no huge imbalance in the `labels` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Crossing Moving Average Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_bars_df_ma = dollar_bars_df.copy(deep=True)\n",
    "dollar_bars_df_ma['ma'] = dollar_bars_df_ma['close'].rolling(30, min_periods=1).mean()\n",
    "\n",
    "def get_upside_bars_ma(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[(df['close'] < df['ma']) & (df.shift(-1)['close'] > df.shift(-1)['ma'])]\n",
    "\n",
    "def get_downside_bars_ma(df: pd.DataFrame) -> np.ndarray:\n",
    "    return df[(df['close'] > df['ma']) & (df.shift(-1)['close'] < df.shift(-1)['ma'])]\n",
    "\n",
    "up_timestamps, down_timestamps = get_upside_bars_ma(dollar_bars_df_ma), get_downside_bars_ma(dollar_bars_df_ma)\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Scatter(x=dollar_bars_df_ma.index, y=dollar_bars_df_ma['close'], line=dict(color=\"blue\", width=1),\n",
    "               name='Close Price')\n",
    ").update_layout(xaxis_title=\"Time\", yaxis_title=\"Price\", title=\"Close Price and MA\")\n",
    "fig.add_trace(go.Scatter(x=dollar_bars_df_ma.index, y=dollar_bars_df_ma['ma'], line=dict(color=\"purple\", width=0.7),\n",
    "                         name='MA20')\n",
    ")\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=up_timestamps.index, y=up_timestamps['close'], mode='markers',\n",
    "    marker=dict(size=3, color='green', symbol=5), name='Upside Timestamps')\n",
    ")\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=down_timestamps.index, y=down_timestamps['close'], mode='markers',\n",
    "    marker=dict(size=3, color='red', symbol=6), name='Downside Timestamps')\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to derive metalabels using the events from the previous task (but now we have sides of bets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_index = up_timestamps.index.union(down_timestamps.index)\n",
    "side_data = []\n",
    "for idx in side_index:\n",
    "    if idx in up_timestamps.index:\n",
    "        side_data.append(1)\n",
    "    else:\n",
    "        side_data.append(-1)\n",
    "side = pd.Series(data=side_data, index=side_index)\n",
    "\n",
    "events_ma = get_events_tripple_barrier(close=dollar_bars_df['close'], tEvents=tEvents, pt_sl=[1, 2],\n",
    "                                       trgt=get_daily_vol(dollar_bars_df['close']), minRet=0.007,\n",
    "                                       numThreads=1, t1=t1, side=side)\n",
    "events_ma = events_ma.dropna()\n",
    "events_ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to get the bins corresponding to chosen events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_ma = get_bins(close=dollar_bars_df_ma['close'], events=events_ma, t1=t1)\n",
    "bins_ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train random forest to decide whether to trade or not. Here the only feature is the decision of the first-level algorithm - the side of the bet. In out case these are the sides given by the MA Crossing strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(rf: RandomForestClassifier, X_test: np.ndarray,\n",
    "                  y_test: np.ndarray, y_pred: np.ndarray) -> None:\n",
    "    print(f'RF accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'RF precision: {precision_score(y_test, y_pred)}')\n",
    "    print(f'RF recall: {recall_score(y_test, y_pred)}')\n",
    "    plot_roc_curve(rf, X_test, y_test)\n",
    "\n",
    "X, y = events_ma['side'].values.reshape(-1, 1), bins_ma['bin'].values.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print_results(rf, X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bollinger Bands Mean-Reverting Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do practically the same thing but use Bollinger bands as the primary model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bollinger_bands(dollar_bars: pd.DataFrame, alpha: float) -> np.ndarray:\n",
    "    prices = dollar_bars['close']                                    # taking close prices\n",
    "    ma = (prices.rolling(30, min_periods=1).mean())                  # 30 bars moving average\n",
    "    sigma = prices.rolling(30, min_periods=1).std()\n",
    "    sigma[0] = 0\n",
    "    b_upper, b_lower = (ma + alpha * sigma), (ma - alpha * sigma)    # bollinger bounds    \n",
    "    return np.array([ma, b_upper, b_lower])\n",
    "\n",
    "ma, b_upper, b_lower = get_bollinger_bands(dollar_bars_df, 1)\n",
    "dollar_bars_df_bb = dollar_bars_df.copy(deep=True)\n",
    "dollar_bars_df_bb['ma'], dollar_bars_df_bb['b_upper'], dollar_bars_df_bb['b_lower'] = ma, b_upper, b_lower\n",
    "\n",
    "def get_upside_bars_bb(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[(df['open'] < df['b_upper']) & (df['close'] > df['b_upper'])]\n",
    "\n",
    "def get_downside_bars_bb(df: pd.DataFrame) -> np.ndarray:\n",
    "    return df[(df['open'] > df['b_lower']) & (df['close'] < df['b_lower'])]\n",
    "\n",
    "up_timestamps, down_timestamps = get_upside_bars_bb(dollar_bars_df_bb), get_downside_bars_bb(dollar_bars_df_bb)\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Scatter(x=dollar_bars_df_bb.index, y=dollar_bars_df_bb['close'], line=dict(color=\"blue\", width=1),\n",
    "               name='Close Price')\n",
    ").update_layout(xaxis_title=\"Time\", yaxis_title=\"Price\", title=\"Close Price\")\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=up_timestamps.index, y=up_timestamps['close'], mode='markers',\n",
    "    marker=dict(size=3, color='green', symbol=5), name='Upside Timestamps')\n",
    ")\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=down_timestamps.index, y=down_timestamps['close'], mode='markers',\n",
    "    marker=dict(size=3, color='red', symbol=6), name='Downside Timestamps')\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_index = up_timestamps.index.union(down_timestamps.index)\n",
    "side_data = []\n",
    "for idx in side_index:\n",
    "    if idx in up_timestamps.index:\n",
    "        side_data.append(1)\n",
    "    else:\n",
    "        side_data.append(-1)\n",
    "side = pd.Series(data=side_data, index=side_index)\n",
    "\n",
    "events_bb = get_events_tripple_barrier(close=dollar_bars_df['close'], tEvents=tEvents, pt_sl=[0, 2],\n",
    "                                       trgt=get_daily_vol(dollar_bars_df['close']), minRet=0.007,\n",
    "                                       numThreads=1, t1=t1, side=side)\n",
    "events_bb = events_bb.dropna()\n",
    "events_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_bb = get_bins(close=dollar_bars_df_bb['close'], events=events_bb, t1=t1)\n",
    "bins_bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the secondary random forest model. Apart from the sides given by the primary model, I add volatility and autocorreation to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(\n",
    "    {'vol': get_daily_vol(dollar_bars_df['close']),\n",
    "     'autocorr': dollar_ret.rolling(20, min_periods=1).corr(dollar_ret.shift(1)).dropna(),\n",
    "     'side': events_bb['side']}\n",
    ").dropna()\n",
    "X = X[~X.index.duplicated(keep='first')]\n",
    "y = bins_bb['bin'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print_results(rf, X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare results of this 2-level model to results that can be achieved by using only primary model (based on Bollinger bands):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change classes from {-1, -1} to {0, 1}\n",
    "y_pred_primary = ((pd.concat((events_bb, bins_bb), axis=1)['side'] + 1) / 2).astype(int)[-X_test.shape[0]:]\n",
    "\n",
    "print(f'Primary model accuracy: {accuracy_score(y_test, y_pred_primary)}')\n",
    "print(f'Primary model precision: {precision_score(y_test, y_pred_primary)}')\n",
    "print(f'Primary model recall: {recall_score(y_test, y_pred_primary)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
